{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1 style=\"color:#961296; text-align:center;\">Multilingual translation tool for SimpleSite</H1>\n",
    "<div style=\"color:#962412;\">\n",
    "<H3>Purpose</H3>\n",
    "The aim of this tool is to facilitate continuous updates to the language files for SimpleSite's website creation platform.\n",
    "\n",
    "<H3>Challange</H3>\n",
    "Currenly, update files from language supporters containing new keys or modyfied values are in XML format and target language files are in JSON format. That makes not possible to use merge tools to apply language changes and the procedure has to be handled manually.\n",
    "\n",
    "<H3>Proposed solution</H3> \n",
    "<H5>Number 1  ~> XML to JSON conversion</H5>\n",
    "One way is to convert provided XML file to exact corresponding JSON format, hence allowing to compare new  and old values in a merge tool of one's choice.\n",
    "<img src=\"http://i.imgur.com/vpv0KFZ.png\">\n",
    "<H5>Number 2 ~> Automated merge</H5>\n",
    "The ideal way would be attempt an automated merge of the chages into the language files\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<H3 style=\"color:#961296;\">XML to JSON conversion</H3> \n",
    "<div style=\"color:#962412;\">\n",
    "<h5>Description</h5>\n",
    "This procedure converts XML files provided in 'XML_files' directory to desired JSON format and saves each of the dataset in text file in 'Text_files' directory.\n",
    "<h5>Remarks</h5>\n",
    "Currently, the files are saved with LF newline with a white space at the end of most lines, whereas language files the changes will be merged to have CRLF new lines.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from xml.dom import minidom\n",
    "from pprint import pprint\n",
    "from collections import OrderedDict\n",
    "from xml.parsers import expat\n",
    "import codecs\n",
    "\n",
    "# Lanuage codes of the files to be updated\n",
    "langCodes = ['de', 'it', 'fr', 'nl', 'nb', 'sv', 'da', 'ru']\n",
    "\n",
    "# test file with a few sample items\n",
    "langCodes = ['it']\n",
    "\n",
    "# Iterate through selected languages\n",
    "for lc in langCodes:\n",
    "    \n",
    "    # Parse HML file with current language to minidom format\n",
    "    xmldoc = minidom.parse('XML_files/translation_'+ lc +'.xml')\n",
    "    \n",
    "    # Extract all items by their name 'unit' \n",
    "    itemlist = xmldoc.getElementsByTagName('unit')\n",
    "    \n",
    "    # there are 4 set of translations files \n",
    "    transtationFolders = ['base', 'home', 'login', 'signup']\n",
    "    \n",
    "    # iterate through all translation sets\n",
    "    for tf in transtationFolders:\n",
    "        \n",
    "        # open current translation file to me updated\n",
    "        with open('original_json_files/'+ tf +'/'+ lc +'.json') as json_data:\n",
    "            translations = json.load(json_data)\n",
    "    \n",
    "        # iterate through each item from XML file\n",
    "        for item in reversed(itemlist):\n",
    "\n",
    "            # get item's id which a set of nested keys f.ex. \"HOME.DESIGN_EDITOR.BACKGROUND\"\n",
    "            unitId = item.attributes['id'].value\n",
    "            # split id by the '.' to individual keys\n",
    "            keys = unitId.split('.')\n",
    "            # get item's value\n",
    "            sourceVal = item.getElementsByTagName('source').item(0).firstChild.nodeValue\n",
    "\n",
    "            # first key determines translation set it is\n",
    "            if keys[0].lower() == tf:\n",
    "\n",
    "                # build nested dictionary\n",
    "                parentNode = translations\n",
    "                for idx, key in enumerate(keys):\n",
    "                    # if last element, add translation value to the current key\n",
    "                    if idx == len(keys)-1:\n",
    "                        parentNode[key] = sourceVal\n",
    "                    # else, if key exist, add itself of create a new dictionary and step down the tree\n",
    "                    else:\n",
    "                        childNode = parentNode\n",
    "                        childNode[key] = childNode.get(key, {})\n",
    "                        parentNode = childNode[key]\n",
    "\n",
    "        # save each language data to file encoded in ISO-8859-1 unicode\n",
    "        with codecs.open('updated_json_files/'+ tf +'/updated_'+ lc +'.json', 'w', encoding=\"UTF-8\") as f:\n",
    "            # sort each nested dictionary alphabetically and apply a new line with 2 space indent\n",
    "            json.dump(translations, f, indent=2, sort_keys=True, ensure_ascii = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3 style=\"color:#961296;\">Spreadsheet to JSON conversion</H3> \n",
    "<img src=\"https://i.imgur.com/dkHI1F9.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from xml.dom import minidom\n",
    "from pprint import pprint\n",
    "from collections import OrderedDict\n",
    "from xml.parsers import expat\n",
    "import codecs\n",
    "\n",
    "lang_files_path = 'C:/123/frontendprototype/app/src/translations/'\n",
    "items_delimiter = '\\n'\n",
    "keys_delimiter = '\\t'\n",
    "encoding_key = 'UTF-8'\n",
    "\n",
    "file = open('TXT_Files/all.txt', 'r', encoding=encoding_key)\n",
    "items = file.read().split(items_delimiter)\n",
    "\n",
    "# take language keys from the first row and remove first index of that row\n",
    "langs =  items[0].split(keys_delimiter)\n",
    "langs.pop(0)\n",
    "\n",
    "# loop through languages\n",
    "for lang_idx, lang in enumerate(langs):\n",
    "    \n",
    "    # loop through translation sets\n",
    "    for trans_set in ['base', 'home']:\n",
    "        \n",
    "        # open current translation file to me updated\n",
    "        with open(lang_files_path + trans_set +'/'+ lang +'.json', encoding=encoding_key) as json_data:\n",
    "            translations = json.load(json_data)\n",
    "\n",
    "        # Extract data from each translation entry\n",
    "        for item in items:\n",
    "            item_elements = item.split(keys_delimiter)\n",
    "\n",
    "            # Get keys f.ex. \"HOME.DESIGN_EDITOR.BACKGROUND\" and split by the '.' to individual keys\n",
    "            keys = item_elements[0].split('.')\n",
    "            # get item's value\n",
    "            sourceVal = item_elements[lang_idx+1]\n",
    "\n",
    "            # first key determines translation set it is\n",
    "            if keys[0].lower() == trans_set:\n",
    "\n",
    "                # build nested dictionary\n",
    "                parentNode = translations\n",
    "\n",
    "                for idx, key in enumerate(keys):\n",
    "                    # if last element, add translation value to the current key\n",
    "                    if idx == len(keys)-1:\n",
    "                        parentNode[key] = sourceVal\n",
    "                    # else, if key exist, add itself of create a new dictionary and step down the tree\n",
    "                    else:\n",
    "                        childNode = parentNode\n",
    "                        childNode[key] = childNode.get(key, {})\n",
    "                        parentNode = childNode[key]\n",
    "\n",
    "        # save each language data to file\n",
    "        with codecs.open(lang_files_path + trans_set +'/'+ lang +'.json', 'w', encoding=encoding_key) as f:\n",
    "            # sort each nested dictionary alphabetically and apply a new line with 2 space indent\n",
    "            json.dump(translations, f, indent=2, sort_keys=True, ensure_ascii = False)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
